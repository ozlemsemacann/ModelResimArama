import streamlit as st
import numpy as np
import pandas as pd
from PIL import Image, ImageOps
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import os
import requests
from io import BytesIO

st.set_page_config(page_title="AkÄ±llÄ± GÃ¶rsel Arama", layout="wide")

# -----------------------------------------------------------------------------
# 1. YÃœKLEME FONKSÄ°YONLARI
# -----------------------------------------------------------------------------
@st.cache_resource
def load_model():
    return SentenceTransformer("clip-ViT-B-16", device="cpu")

@st.cache_data
def load_data():
    if not os.path.exists("embeddings.npy") or not os.path.exists("images.xlsx"):
        return None, None, "Veri dosyalarÄ± eksik! LÃ¼tfen Ã¶nce 'create_embeddings.py' dosyasÄ±nÄ± Ã§alÄ±ÅŸtÄ±rÄ±n."
    
    try:
        embs = np.load("embeddings.npy")
        df = pd.read_excel("images.xlsx")
        # Veri temizliÄŸi
        df = df.apply(lambda x: x.str.strip() if x.dtype == "object" else x)
        return embs, df, None
    except Exception as e:
        return None, None, f"Dosya okuma hatasÄ±: {str(e)}"

def get_url_from_row(row):
    """Excel satÄ±rÄ±ndan URL'yi bulur."""
    possible_cols = ['link', 'url', 'image_url', 'resim_link', 'gorsel_link', 'image', 'resim']
    for col in row.index:
        if str(col).lower() in possible_cols or (isinstance(row[col], str) and str(row[col]).startswith('http')):
            return row[col]
    return None

def get_filterable_columns(df):
    """Filtre olmaya uygun sÃ¼tunlarÄ± bulur."""
    filter_cols = []
    priority_keywords = ['kategori', 'category', 'grup', 'group', 'cinsiyet', 'gender', 
                         'hedef', 'tip', 'type', 'stil', 'style', 'kalÄ±p', 'fit']
    
    for col in df.columns:
        if "url" in str(col).lower() or "link" in str(col).lower(): continue
            
        if df[col].dtype == 'object' or isinstance(df[col].dtype, pd.CategoricalDtype):
            unique_count = df[col].nunique()
            is_priority = any(k in str(col).lower() for k in priority_keywords)
            if unique_count < 50 and (unique_count > 1 or is_priority):
                filter_cols.append(col)
    return filter_cols

# -----------------------------------------------------------------------------
# 2. ARAYÃœZ VE MANTIK
# -----------------------------------------------------------------------------
st.title("ğŸ” AkÄ±llÄ± ÃœrÃ¼n EÅŸleÅŸtirme")
st.markdown("ÃœrÃ¼n tipi ve kalÄ±bÄ±na gÃ¶re benzer Ã¼rÃ¼nleri bulun.")

# Ã–nbellek Temizleme Butonu
if st.sidebar.button("ğŸ”„ Verileri ve Ã–nbelleÄŸi Yenile"):
    st.cache_data.clear()
    st.rerun()

model = load_model()
embeddings, df, error = load_data()

if error:
    st.error(f"âš ï¸ {error}")
    st.stop()

# --- KENAR Ã‡UBUÄU ---
st.sidebar.header("âš™ï¸ Arama AyarlarÄ±")

# 1. "RENK Ã–NEMLÄ° DEÄÄ°L" MODU
st.sidebar.subheader("ğŸ¯ Arama Modu")
ignore_color = st.sidebar.toggle("Renkleri Yoksay (KalÄ±p OdaklÄ±)", value=True, 
                               help="AÃ§Ä±k olduÄŸunda: Resmin renklerini siler ve kontrastÄ± artÄ±rarak sadece Ã¼rÃ¼nÃ¼n kalÄ±bÄ±na/ÅŸekline odaklanÄ±r.")

# 2. FÄ°LTRELER
st.sidebar.subheader("ğŸ“‚ Filtreler")
filter_columns = get_filterable_columns(df)
active_filters = {}
filtered_indices = df.index.tolist()

if filter_columns:
    for col in filter_columns:
        unique_vals = sorted([str(x) for x in df[col].dropna().unique()])
        options = ["TÃ¼mÃ¼"] + unique_vals
        selection = st.sidebar.selectbox(f"{col}", options, key=col)
        if selection != "TÃ¼mÃ¼":
            active_filters[col] = selection

    if active_filters:
        mask = pd.Series([True] * len(df))
        for col, val in active_filters.items():
            mask = mask & (df[col].astype(str) == val)
        filtered_indices = df[mask].index.tolist()
        st.sidebar.success(f"âœ… Filtrelenen: {len(filtered_indices)} Ã¼rÃ¼n")
    else:
        st.sidebar.info(f"TÃ¼m veritabanÄ± taranÄ±yor ({len(df)} Ã¼rÃ¼n)")
else:
    st.sidebar.warning("Excel'de kategori sÃ¼tunu bulunamadÄ±.")

top_k = st.sidebar.slider("Benzerlik SayÄ±sÄ±", 1, 10, 3)

# --- RESÄ°M YÃœKLEME ---
uploaded_file = st.file_uploader("Referans GÃ¶rsel YÃ¼kle", type=["jpg", "png", "jpeg"])

if uploaded_file:
    col_left, col_right = st.columns([1, 2])
    
    # 1. RESÄ°M Ä°ÅLEME VE GÃ–STERÄ°M
    with col_left:
        st.subheader("ğŸ“¤ Aranan")
        original_img = Image.open(uploaded_file).convert("RGB")
        
        # GÃ¶rÃ¼ntÃ¼ Ä°ÅŸleme MantÄ±ÄŸÄ±
        if ignore_color:
            # 1. Grayscale yap (Rengi at)
            gray_img = ImageOps.grayscale(original_img)
            # 2. Histogram EÅŸitleme (KontrastÄ± patlat - Åekli/Doku'yu Ã¶ne Ã§Ä±kar)
            # Bu iÅŸlem, modelin "siyah pantolon" ile "mavi pantolon" arasÄ±ndaki renk farkÄ±nÄ± gÃ¶rmesini engeller,
            # bunun yerine "bacak ÅŸekli", "cep detaylarÄ±" gibi yapÄ±sal Ã¶zelliklere odaklanmasÄ±nÄ± saÄŸlar.
            enhanced_img = ImageOps.equalize(gray_img)
            query_img = enhanced_img.convert("RGB")
            
            st.image(original_img, caption="Orijinal", use_container_width=True)
            st.caption("ğŸ‘€ Yapay Zeka Bunu GÃ¶rÃ¼yor (Åekil OdaklÄ±):")
            st.image(query_img, use_container_width=True)
        else:
            query_img = original_img
            st.image(query_img, use_container_width=True)
        
    # 2. HESAPLAMA
    with st.spinner("KalÄ±p ve tip analizi yapÄ±lÄ±yor..."):
        if len(filtered_indices) == 0:
            st.error("Filtre sonucunda Ã¼rÃ¼n kalmadÄ±. LÃ¼tfen filtreleri gevÅŸetin.")
            st.stop()

        query_emb = model.encode(query_img)
        filtered_embeddings = embeddings[filtered_indices]
        
        sims = cosine_similarity([query_emb], filtered_embeddings)[0]
        sorted_local_indices = np.argsort(sims)[-top_k:][::-1]
        
    # 3. SONUÃ‡LAR
    with col_right:
        st.subheader(f"ğŸ“Œ Tip Olarak En Benzer {top_k} SonuÃ§")
        
        for local_idx in sorted_local_indices:
            score = sims[local_idx]
            global_idx = filtered_indices[local_idx]
            row = df.iloc[global_idx]
            url = get_url_from_row(row)
            
            with st.container(border=True):
                c1, c2 = st.columns([1, 3])
                
                with c1:
                    if url:
                        st.image(url, width=120)
                    else:
                        st.image("https://placehold.co/120x150?text=Resim+Yok", width=120)
                
                with c2:
                    st.markdown(f"**Benzerlik:** %{score*100:.1f}")
                    if active_filters:
                        st.caption("Filtreye Uygun")
                    
                    details = {k:v for k,v in row.to_dict().items() if str(v) != str(url) and pd.notna(v)}
                    st.json(details, expanded=False)